[ollama]
# Ollama API endpoint
url = https://ai.internal.boehmecke.org
model = qwen2.5-coder:3b
timeout = 300
verify_ssl = false

# Minimum diagnostic commands required before AI can conclude
min_commands_required = 10

# AI model parameters
temperature = 0.7
num_ctx = 16384
num_predict = 1024
top_p = 0.9
top_k = 40
repeat_penalty = 1.3
